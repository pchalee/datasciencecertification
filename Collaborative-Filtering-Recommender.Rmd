---
title: "Collaborative Filtering Recommender System"
author: "Veerasak Kritsanapraphan"
date: "February 15, 2020"
output:
  word_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
---

```{r setup, include = FALSE}
# my global options defined for each code chunk.
knitr::opts_chunk$set(fig.width=7, fig.height=5, echo=FALSE, warning=FALSE, message=FALSE, comment = '')
```

## Introduction

This is an introduction to building Recommender Systems using R. The major CRAN approved package available in R with developed algorithms is called `recommenderlab` by Michael Hahsler. Latest [documentation](https://cran.r-project.org/web/packages/recommenderlab/recommenderlab.pdf) and a [vignette](https://cran.r-project.org/web/packages/recommenderlab/vignettes/recommenderlab.pdf) are both available for exploration. The code examples provided in this exploratory analysis came primarily through the material on Collaborative Filtering algorithms from this package, explored in the book [*Building a Recommendation System with R*](https://smile.amazon.com/Building-Recommendation-System-Suresh-Gorakala/dp/1783554495/ref=sr_1_1?ie=UTF8&qid=1507314554&sr=8-1&keywords=building+a+recommendation+system+R), by Suresh K. Gorakala and Michele Usuelli. 

## Collaborative Filtering

Under *user-based collaborative filtering*, this memory-based method works under the assumption that users with similar item tastes will rate items similarly. Therefore, the missing ratings for a user can be predicted by finding other similar users (a neighborhood). Within the neighborhood, we can aggregate the ratings of these neighbors on items unknown to the user, as basis for a prediction. We'll explore this one in detail in sections below.

An inverted approach to nearest neighbor based recommendations is *item-based collaborative filtering*. Instead of finding the most similar users to each individual, an algorithm assesses the similarities between the items that are correlated in their ratings or purchase profile amongst all users. 

## Load recommenderlab

``` {r}
library(dplyr)
library(ggplot2)
library(recommenderlab)
```

Some of the preloaded datasets that come with `recommenderlab` for learning and exploring. 

``` {r}
help(package = "recommenderlab")
datasets_available <- data(package = "recommenderlab")
datasets_available$results[,4] # titles
```

We'll work with the already available *Movielense* dataset.

``` {r}
data(MovieLense) # loads dataset
class(MovieLense)
movie_r <- MovieLense 
remove(MovieLense)
```

It is formatted as a `realRatingMatrix` class already, an object class created within `recommenderlab` for efficient storage of user-item ratings matrices. It's been optimized for storing sparse matrices, where almost all of the elements are empty. As an example, compare the object size of *Movielense* as a `realRatingMatrix` vs. a `matrix`. 

``` {r}
library(pryr)
object_size(movie_r)
object_size(as(movie_r, "matrix"))
```

The `realRatingMatrix` for this particular dataset is about 9 times more efficient in conserving memory than a traditional matrix object.

## Exploratory Analysis of the Movielense data

Below is a preview of the ratings matrix of users and their ratings. Rows represent the user indexes.

``` {r }
getRatingMatrix(movie_r[1:10, 1:4])
```


For a particular user such as User 1, they gave an average rating of `r round(rowMeans(movie_r[1, ]), 2)`. 10 of the movies rated by them are shown below. 

``` {r eval = FALSE}
as(movie_r[1, ], "list")[[1]][1:10]
```

The `getRatings` function returns the non-missing ratings values from the matrix as a numeric vector. The following histogram shows the distribution of all movie ratings in the dataset. We can see that ratings typically skew higher, centered around a median rating of 4. 

``` {r echo = TRUE}
summary(getRatings(movie_r))

data.frame(ratings = getRatings(movie_r)) %>%
  ggplot(aes(ratings)) + geom_bar(width = 0.75) +
    labs(title = 'Movielense Ratings Distribution')

```



``` {r }
summary(rowCounts(movie_r))

rowCounts(movie_r) %>%
  data.frame(reviews_per_person = .) %>%
  ggplot(aes(x = reviews_per_person)) + 
    geom_histogram(aes(y = ..density..), binwidth = 20) +
    scale_y_continuous(limits = c(0,.0125), 
                       breaks = seq(0, .0125, by = 0.0025),
                       labels = seq(0, .0125, by = 0.0025)) +
    labs(title = 'Number of Ratings Per MovieLense Reviewer')

```

With a median number of reviews of `r median(colCounts(movie_r))` per user and `r ncol(movie_r)` different movies available to rate, we know that the data is sparse with a lot of users not having rated most of the movies available. 

``` {r }
summary(colCounts(movie_r))

colCounts(movie_r) %>%
  data.frame(movie_review_count = .) %>%
  ggplot(aes(x = movie_review_count)) + 
    geom_histogram(aes(y = ..density..), binwidth = 20) +
    scale_y_continuous(limits = c(0,.0175)) +
    labs(title = 'Number of Reviews Per MovieLense listed Movie')

```

## Recommender Algorithms Available

The recommender algorithms are stored in a registry object called `recommenderRegistry`. We can get a look at the different models based on the different matrix types.

``` {r}
names(recommenderRegistry$get_entries())
```

Since our matrix is a real ratings matrix, we'll call the algorithms available for working on numeric ratings based review data as stored in the `realRatingMatrix`. Here, I've pulled the descriptions of each of the algorithms available for working with real user ratings data. 

``` {r}
vapply(recommenderRegistry$get_entries(dataType = "realRatingMatrix"), 
       '[[', 
       FUN.VALUE = "character", 
       "description")
```

## Exploring User-based Collaborative Filtering

In the algorithms registry, the last algorithm provided in the listing is the one we'll use to explore user-based collaborative filtering (UBCF) to fit the UBCF algorithm to the `realRatingMatrix` of MovieLense reviews data. Information about this algorithm per the registry:

``` {r echo = TRUE}
ubcf_model_description <- tail(recommenderRegistry$get_entries(dataType = "realRatingMatrix"), 1)
ubcf_model_description
```

There are 4 parameters to account for with this model as described above:

* **method**: this is the type of similarity metric to calculate similarity between users real ratings profile. Cosine similarity, Pearson correlation coefficient, and Jaccard similarity are available options. The first two are not good options if using unary ratings, but work well for this scenario.

* **nn**: this parameter sets the neighborhood of most similar users to consider for each user profile. the ratings profiles of the k nearest neighbors will be the basis for making predictions on a users unrated items profile.

* **sample**: a logical value to indicate whether the data should be sampled for train/test. Probably best to explicitely set a reproducible seed and sample the data before running the model.

* **normalize**: how to normalize real ratings provided by different users. This is crucially important b/c all users have a different bias in how they tend to rate items. This can be done by passing a value to this parameter inside the algorithm or applied to the matrix before any modeling too. See `?normalize` for additional details. 

### Normalize the data 

User rating *zero mean centering* will be used for modeling, where each user's vector of ratings is subtracted by its own mean to center the mean at zero. Z-scoring is an alternative method available too that additionally divides each user's rating by its standard deviation. 

** maybe visualize the distribution of user ratings here too after normalization vs. before normalization **
``` {r}
movie_r_norm <- normalize(movie_r, method = 'center') # for visual comparison purposes. 
remove(movie_r_norm)
```

### How the UBCF algorithm works

1. Using cosine similarity, figure out how similar each user is to each other. 
  i) for each user, identify the *k* most similar users. Here, *k* parameter was the 10 most similar users who rated common items most similarly. 
2. Per item, average the ratings by each user's *k* most similar users.
  i) weight the average ratings based on similarity score of each user whose rated the item. Similarity score equals weight, or
  ii) use any of the pythagorean averages, as suits the business case (arithmetic, geometric, harmonic)
3. Select a Top-N recommendations threshold. 


###  Set Up a Model Training & Evaluation Scheme

``` {r echo = TRUE}
train_proportion <- .75
# shouldn't keep n rec. items > min(rowCounts(movie_r))
min(rowCounts(movie_r))
items_per_test_user_keep <- 10
# What's a good rating for a binary split?
good_threshold <- 4

```


``` {r echo = TRUE}
# Building a Recommender System with R by Gorakala and Usuelli. Ch.4 pp 77 - 83
set.seed(123)
model_train_scheme <- movie_r %>%
  evaluationScheme(method = 'split', # single train/test split
                   train = train_proportion, # proportion of rows to train.
                   given = items_per_test_user_keep, # shouldn't keep n rec. items > min(rowCounts(movie_r))
                   goodRating = good_threshold, # for binary classifier analysis.
                   k = 1)

```

Having set our `evaluationScheme` and stored it in an object called *model_train_scheme*, we can fit a UBCF recommender system model. 

``` {r echo = TRUE}
# Building a Recommender System with R by Gorakala and Usuelli. Ch.4 pp 84
model_params <- list(method = "cosine",
                     nn = 10, # find each user's 10 most similar users.
                     sample = FALSE, # already did this.
                     normalize = "center")

model1 <- getData(model_train_scheme, "train") %>% #only fit on the 75% training data.
  Recommender(method = "UBCF", parameter = model_params)
```

### Evaluate Predictive Performance 


``` {r echo = TRUE}
# 5.5 - 5.6. Evaluation of predicted ratings in recommenderLab vignette. can use n = for predicting TopN or type = for predicting ratings.
model1_pred <- predict(model1, getData(model_train_scheme, "known"), type = "ratings")
model1_pred
```

Now we can test the predicion error of model 1 on the *unknown* test user ratings using the `calcPredictionAccuracy` method. Three metrics for ratings test error are available: root mean squared error, mean squared error, or mean absolute error. The results below focus on RMSE with the errors calculated per test user on their *unknown* data. 

```{r echo = TRUE}
test_error <- calcPredictionAccuracy(model1_pred, getData(model_train_scheme, "unknown"), byUser = TRUE)
head(test_error)
```

Let's visualize the distribution of the average RMSE of new predicted ratings for each `r nrow(test_error)` test user.

``` {r}
test_user_error_data <- data.frame(user_id = as.numeric(row.names(test_error)),
                                   rmse = test_error[, 1],
                                   predicted_items_cnt = rowCounts(getData(model_train_scheme, "unknown"))) # coerce from matrix to df.

test_user_error_data %>%
  ggplot(aes(rmse)) +  
    geom_histogram(aes(y = ..density..)) +
    labs(title = 'RMSE on Predicted Recommendations per Test User',
         subtitle = "User-Based Collaborative Filtering using Cosine Similarity")

```


